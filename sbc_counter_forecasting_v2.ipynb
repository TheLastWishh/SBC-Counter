{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d88ffb7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node1_c1</th>\n",
       "      <th>node1_c2</th>\n",
       "      <th>node1_c3</th>\n",
       "      <th>node1_c4</th>\n",
       "      <th>node1_c5</th>\n",
       "      <th>node1_c6</th>\n",
       "      <th>node1_c7</th>\n",
       "      <th>node1_c8</th>\n",
       "      <th>node1_c9</th>\n",
       "      <th>node1_c10</th>\n",
       "      <th>...</th>\n",
       "      <th>node6_c11</th>\n",
       "      <th>node6_c12</th>\n",
       "      <th>node6_c13</th>\n",
       "      <th>node6_c14</th>\n",
       "      <th>node6_c15</th>\n",
       "      <th>node6_c16</th>\n",
       "      <th>node6_c17</th>\n",
       "      <th>node6_c18</th>\n",
       "      <th>node6_c19</th>\n",
       "      <th>node6_c20</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trigger_time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-09-07 18:39:27</th>\n",
       "      <td>22695.0</td>\n",
       "      <td>20238.0</td>\n",
       "      <td>20681.0</td>\n",
       "      <td>19287.0</td>\n",
       "      <td>22703.0</td>\n",
       "      <td>18683.0</td>\n",
       "      <td>19338.0</td>\n",
       "      <td>19689.0</td>\n",
       "      <td>17477.0</td>\n",
       "      <td>18901.0</td>\n",
       "      <td>...</td>\n",
       "      <td>23816.0</td>\n",
       "      <td>18616.0</td>\n",
       "      <td>19922.0</td>\n",
       "      <td>20057.0</td>\n",
       "      <td>18213.0</td>\n",
       "      <td>18327.0</td>\n",
       "      <td>17304.0</td>\n",
       "      <td>19542.0</td>\n",
       "      <td>21080.0</td>\n",
       "      <td>22515.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-09-07 18:44:27</th>\n",
       "      <td>21120.0</td>\n",
       "      <td>19911.0</td>\n",
       "      <td>21249.0</td>\n",
       "      <td>21861.0</td>\n",
       "      <td>18355.0</td>\n",
       "      <td>20104.0</td>\n",
       "      <td>22204.0</td>\n",
       "      <td>20710.0</td>\n",
       "      <td>19171.0</td>\n",
       "      <td>21094.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20085.0</td>\n",
       "      <td>18478.0</td>\n",
       "      <td>21396.0</td>\n",
       "      <td>21944.0</td>\n",
       "      <td>20388.0</td>\n",
       "      <td>18512.0</td>\n",
       "      <td>20991.0</td>\n",
       "      <td>19283.0</td>\n",
       "      <td>18880.0</td>\n",
       "      <td>18020.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-09-07 18:49:27</th>\n",
       "      <td>19024.0</td>\n",
       "      <td>20255.0</td>\n",
       "      <td>19361.0</td>\n",
       "      <td>21907.0</td>\n",
       "      <td>18896.0</td>\n",
       "      <td>19823.0</td>\n",
       "      <td>19579.0</td>\n",
       "      <td>18229.0</td>\n",
       "      <td>21886.0</td>\n",
       "      <td>19680.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20821.0</td>\n",
       "      <td>19749.0</td>\n",
       "      <td>17640.0</td>\n",
       "      <td>22354.0</td>\n",
       "      <td>21744.0</td>\n",
       "      <td>16455.0</td>\n",
       "      <td>18865.0</td>\n",
       "      <td>19036.0</td>\n",
       "      <td>20220.0</td>\n",
       "      <td>17023.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-09-07 18:54:27</th>\n",
       "      <td>19199.0</td>\n",
       "      <td>23258.0</td>\n",
       "      <td>20103.0</td>\n",
       "      <td>19764.0</td>\n",
       "      <td>18378.0</td>\n",
       "      <td>19695.0</td>\n",
       "      <td>18769.0</td>\n",
       "      <td>19945.0</td>\n",
       "      <td>20138.0</td>\n",
       "      <td>18877.0</td>\n",
       "      <td>...</td>\n",
       "      <td>17981.0</td>\n",
       "      <td>19731.0</td>\n",
       "      <td>18713.0</td>\n",
       "      <td>19907.0</td>\n",
       "      <td>21435.0</td>\n",
       "      <td>18740.0</td>\n",
       "      <td>21203.0</td>\n",
       "      <td>20388.0</td>\n",
       "      <td>21997.0</td>\n",
       "      <td>20412.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-09-07 18:59:27</th>\n",
       "      <td>20564.0</td>\n",
       "      <td>22984.0</td>\n",
       "      <td>17187.0</td>\n",
       "      <td>19524.0</td>\n",
       "      <td>21141.0</td>\n",
       "      <td>20346.0</td>\n",
       "      <td>18875.0</td>\n",
       "      <td>20374.0</td>\n",
       "      <td>20394.0</td>\n",
       "      <td>17472.0</td>\n",
       "      <td>...</td>\n",
       "      <td>19279.0</td>\n",
       "      <td>19909.0</td>\n",
       "      <td>21264.0</td>\n",
       "      <td>20723.0</td>\n",
       "      <td>19466.0</td>\n",
       "      <td>23496.0</td>\n",
       "      <td>24569.0</td>\n",
       "      <td>19481.0</td>\n",
       "      <td>19262.0</td>\n",
       "      <td>20204.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 120 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     node1_c1  node1_c2  node1_c3  node1_c4  node1_c5  \\\n",
       "trigger_time                                                            \n",
       "2025-09-07 18:39:27   22695.0   20238.0   20681.0   19287.0   22703.0   \n",
       "2025-09-07 18:44:27   21120.0   19911.0   21249.0   21861.0   18355.0   \n",
       "2025-09-07 18:49:27   19024.0   20255.0   19361.0   21907.0   18896.0   \n",
       "2025-09-07 18:54:27   19199.0   23258.0   20103.0   19764.0   18378.0   \n",
       "2025-09-07 18:59:27   20564.0   22984.0   17187.0   19524.0   21141.0   \n",
       "\n",
       "                     node1_c6  node1_c7  node1_c8  node1_c9  node1_c10  ...  \\\n",
       "trigger_time                                                            ...   \n",
       "2025-09-07 18:39:27   18683.0   19338.0   19689.0   17477.0    18901.0  ...   \n",
       "2025-09-07 18:44:27   20104.0   22204.0   20710.0   19171.0    21094.0  ...   \n",
       "2025-09-07 18:49:27   19823.0   19579.0   18229.0   21886.0    19680.0  ...   \n",
       "2025-09-07 18:54:27   19695.0   18769.0   19945.0   20138.0    18877.0  ...   \n",
       "2025-09-07 18:59:27   20346.0   18875.0   20374.0   20394.0    17472.0  ...   \n",
       "\n",
       "                     node6_c11  node6_c12  node6_c13  node6_c14  node6_c15  \\\n",
       "trigger_time                                                                 \n",
       "2025-09-07 18:39:27    23816.0    18616.0    19922.0    20057.0    18213.0   \n",
       "2025-09-07 18:44:27    20085.0    18478.0    21396.0    21944.0    20388.0   \n",
       "2025-09-07 18:49:27    20821.0    19749.0    17640.0    22354.0    21744.0   \n",
       "2025-09-07 18:54:27    17981.0    19731.0    18713.0    19907.0    21435.0   \n",
       "2025-09-07 18:59:27    19279.0    19909.0    21264.0    20723.0    19466.0   \n",
       "\n",
       "                     node6_c16  node6_c17  node6_c18  node6_c19  node6_c20  \n",
       "trigger_time                                                                \n",
       "2025-09-07 18:39:27    18327.0    17304.0    19542.0    21080.0    22515.0  \n",
       "2025-09-07 18:44:27    18512.0    20991.0    19283.0    18880.0    18020.0  \n",
       "2025-09-07 18:49:27    16455.0    18865.0    19036.0    20220.0    17023.0  \n",
       "2025-09-07 18:54:27    18740.0    21203.0    20388.0    21997.0    20412.0  \n",
       "2025-09-07 18:59:27    23496.0    24569.0    19481.0    19262.0    20204.0  \n",
       "\n",
       "[5 rows x 120 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"sbc_counter_result.csv\")\n",
    "\n",
    "# 1. Loại bỏ cột không dùng\n",
    "df = df.drop(columns=['id', 'counter_option'])\n",
    "\n",
    "# 2. Chuyển trigger_time -> datetime\n",
    "df['trigger_time'] = pd.to_datetime(df['trigger_time'], unit='s')\n",
    "\n",
    "# 3. Pivot: mỗi time step là 1 dòng, cột là (node_id, counter_id)\n",
    "pivot_df = df.pivot_table(\n",
    "    index='trigger_time',          # trục thời gian\n",
    "    columns=['node_id', 'counter_id'],\n",
    "    values='counter_value'\n",
    ").sort_index()\n",
    "\n",
    "# Bỏ multiindex, tạo tên cột dạng \"nodeX_counterY\"\n",
    "pivot_df.columns = [f\"node{n}_c{c}\" for (n, c) in pivot_df.columns]\n",
    "pivot_df = pivot_df.dropna()   # đơn giản: bỏ missing, hoặc bạn có thể fillna\n",
    "pivot_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d17cb91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số feature tổng: 120\n",
      "Số cột target (n_nodes * n_counter): 18\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "all_features = pivot_df.columns.tolist()\n",
    "\n",
    "# Ví dụ: tất cả cột có counter_id 1,2,3 là target\n",
    "target_counter_ids = [1, 2, 3]\n",
    "\n",
    "# Lọc tên cột target dựa trên pattern \"nodeX_cY\"\n",
    "target_cols = [col for col in all_features \n",
    "               if any(col.endswith(f\"_c{cid}\") for cid in target_counter_ids)]\n",
    "\n",
    "print(\"Số feature tổng:\", len(all_features))\n",
    "print(\"Số cột target (n_nodes * n_counter):\", len(target_cols))\n",
    "\n",
    "# Chuẩn hóa theo toàn bộ cột (model học quan hệ trên toàn bộ)\n",
    "scaler = MinMaxScaler()\n",
    "data_scaled = scaler.fit_transform(pivot_df.values)\n",
    "data_scaled = pd.DataFrame(data_scaled, index=pivot_df.index, columns=all_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dca2091f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số feature tổng: 120\n",
      "Số cột target (n_nodes * n_counter): 18\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "all_features = pivot_df.columns.tolist()\n",
    "\n",
    "# Ví dụ: tất cả cột có counter_id 1,2,3 là target\n",
    "target_counter_ids = [1, 2, 3]\n",
    "\n",
    "# Lọc tên cột target dựa trên pattern \"nodeX_cY\"\n",
    "target_cols = [col for col in all_features \n",
    "               if any(col.endswith(f\"_c{cid}\") for cid in target_counter_ids)]\n",
    "\n",
    "print(\"Số feature tổng:\", len(all_features))\n",
    "print(\"Số cột target (n_nodes * n_counter):\", len(target_cols))\n",
    "\n",
    "# Chuẩn hóa theo toàn bộ cột (model học quan hệ trên toàn bộ)\n",
    "scaler = MinMaxScaler()\n",
    "data_scaled = scaler.fit_transform(pivot_df.values)\n",
    "data_scaled = pd.DataFrame(data_scaled, index=pivot_df.index, columns=all_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11ea56cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (26185, 24, 120)\n",
      "Y shape: (26185, 18)\n"
     ]
    }
   ],
   "source": [
    "def create_sequences(data_scaled, target_cols, n_past=24, n_future=1):\n",
    "    \"\"\"\n",
    "    data_scaled: DataFrame (T, n_features_total)\n",
    "    target_cols: list tên cột target\n",
    "    return:\n",
    "        X: (N, n_past, n_features_total)\n",
    "        Y: (N, n_outputs)  # flatten toàn bộ node & counter\n",
    "        time_index: index thời gian của Y (lúc dự đoán)\n",
    "    \"\"\"\n",
    "    X, Y, time_index = [], [], []\n",
    "    feature_values = data_scaled.values\n",
    "    target_idx = [data_scaled.columns.get_loc(c) for c in target_cols]\n",
    "    \n",
    "    for i in range(n_past, len(data_scaled) - n_future + 1):\n",
    "        # input: [i-n_past, i)\n",
    "        X.append(feature_values[i - n_past:i, :])   # (n_past, n_features_total)\n",
    "        \n",
    "        # output tại time i + n_future - 1\n",
    "        y_step = feature_values[i + n_future - 1, target_idx]  # (n_outputs,)\n",
    "        Y.append(y_step)\n",
    "        \n",
    "        time_index.append(data_scaled.index[i + n_future - 1])\n",
    "    \n",
    "    return np.array(X), np.array(Y), np.array(time_index)\n",
    "\n",
    "n_past = 24   # ví dụ: 24 bước (5p → 2h), bạn thay theo ý\n",
    "n_future = 1\n",
    "\n",
    "X, Y, time_index = create_sequences(data_scaled, target_cols, n_past, n_future)\n",
    "\n",
    "print(\"X shape:\", X.shape)  # (N, n_past, n_features_total)\n",
    "print(\"Y shape:\", Y.shape)  # (N, n_nodes * n_counter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4417b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\acer\\anaconda3\\envs\\zhuge\\lib\\site-packages\\google\\api_core\\_python_version_support.py:266: FutureWarning: You are using a Python version (3.10.18) which Google will stop supporting in new releases of google.api_core once it reaches its end of life (2026-10-04). Please upgrade to the latest Python version, or at least Python 3.11, to continue receiving updates for google.api_core past that date.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Dense, Embedding, LSTM, Dropout, Reshape,\n",
    "    TimeDistributed, Concatenate, Lambda\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import MultiHeadAttention\n",
    "\n",
    "\n",
    "def build_lstm_node_counter_model(\n",
    "    n_past: int,\n",
    "    n_nodes: int,\n",
    "    n_counters_total: int,\n",
    "    n_counters_target: int,\n",
    "    n_nodes_total: int,           # tổng số node_id có thể có (để embedding)\n",
    "    counter_latent_dim: int = 8,  # H: latent dim cho counter\n",
    "    node_emb_dim: int = 16,       # E: embedding dim cho node\n",
    "    lstm_units: int = 64,\n",
    "    dropout_rate: float = 0.2\n",
    "):\n",
    "    \"\"\"\n",
    "    Trả về model:\n",
    "      Input 1: counters_input  (batch, T=n_past, N=n_nodes, C=n_counters_total)\n",
    "      Input 2: node_ids_input  (N=n_nodes,) int32   -- danh sách node_id cố định\n",
    "\n",
    "      Output:  (batch, N, K=n_counters_target)\n",
    "    \"\"\"\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # 1. Khai báo input\n",
    "    # ------------------------------------------------------\n",
    "    # Dữ liệu counter: (batch, T, N, C)\n",
    "    counters_input = Input(\n",
    "        shape=(n_past, n_nodes, n_counters_total),\n",
    "        name=\"counters_input\"\n",
    "    )\n",
    "\n",
    "    # node_ids cho N node, cố định theo batch & time\n",
    "    # Ví dụ: [0,1,2,3,4,5] hoặc [101, 102, ...]\n",
    "    node_ids_input = Input(\n",
    "        shape=(n_nodes,),\n",
    "        dtype=\"int32\",\n",
    "        name=\"node_ids_input\"\n",
    "    )\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # 2. Counter encoder (giảm chiều C -> H)\n",
    "    #    TimeDistributed(TimeDistributed(Dense))\n",
    "    # ------------------------------------------------------\n",
    "    # Mỗi node, mỗi time-step: Dense(C -> H)\n",
    "    counter_encoder_dense = Dense(\n",
    "        counter_latent_dim,\n",
    "        activation=\"relu\",\n",
    "        name=\"counter_encoder_dense\"\n",
    "    )\n",
    "\n",
    "    # Áp dụng theo trục node (N)\n",
    "    per_node_encoded = TimeDistributed(\n",
    "        counter_encoder_dense,\n",
    "        name=\"counter_encoder_per_node\"   # (batch, T, N, H)\n",
    "    )\n",
    "\n",
    "    # Áp dụng theo trục thời gian (T)\n",
    "    encoded_counters = TimeDistributed(\n",
    "        per_node_encoded,\n",
    "        name=\"counter_encoder_per_time\"\n",
    "    )(counters_input)  # (batch, T, N, H)\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # 3. Node embedding + broadcast ra (batch, T, N, E)\n",
    "    # ------------------------------------------------------\n",
    "    node_embedding_layer = Embedding(\n",
    "        input_dim=n_nodes_total,\n",
    "        output_dim=node_emb_dim,\n",
    "        name=\"node_embedding\"\n",
    "    )\n",
    "    # node_emb: (N, E)\n",
    "    node_emb = node_embedding_layer(node_ids_input)\n",
    "\n",
    "    # Broadcast node_emb theo batch & time\n",
    "    def broadcast_node_emb(inputs):\n",
    "        node_emb, x = inputs  # node_emb: (N,E), x: (B,T,N,C)\n",
    "        B = tf.shape(x)[0]\n",
    "        T = tf.shape(x)[1]\n",
    "        N = tf.shape(x)[2]\n",
    "        E = tf.shape(node_emb)[1]\n",
    "\n",
    "        # (N,E) -> (1,1,N,E)\n",
    "        node_emb_exp = tf.reshape(node_emb, (1, 1, N, E))\n",
    "        # tile ra (B,T,N,E)\n",
    "        node_emb_exp = tf.tile(node_emb_exp, [B, T, 1, 1])\n",
    "        return node_emb_exp\n",
    "\n",
    "    node_emb_broadcast = Lambda(\n",
    "        broadcast_node_emb,\n",
    "        name=\"broadcast_node_embedding\"\n",
    "    )([node_emb, counters_input])  # (B,T,N,E)\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # 4. Ghép counter latent + node embedding  => (B,T,N,F)\n",
    "    # ------------------------------------------------------\n",
    "    node_feature = Concatenate(axis=-1, name=\"concat_counter_node\")(\n",
    "        [encoded_counters, node_emb_broadcast]\n",
    "    )  # (B,T,N,H+E)\n",
    "    feature_dim = counter_latent_dim + node_emb_dim  # F\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # 5. Self-Attention theo node (trong cùng 1 time-step)\n",
    "    #    - reshape (B,T,N,F) -> (B*T, N, F)\n",
    "    #    - MultiHeadAttention\n",
    "    #    - reshape lại (B,T,N,F)\n",
    "    # ------------------------------------------------------\n",
    "    node_mha = MultiHeadAttention(\n",
    "        num_heads=1,       # đơn giản: 1 head, có thể tăng\n",
    "        key_dim=feature_dim,\n",
    "        name=\"node_mha\"\n",
    "    )\n",
    "\n",
    "    def apply_node_attention(x):\n",
    "        # x: (B,T,N,F)\n",
    "        B = tf.shape(x)[0]\n",
    "        T = tf.shape(x)[1]\n",
    "        N = tf.shape(x)[2]\n",
    "        F = tf.shape(x)[3]\n",
    "\n",
    "        x_reshaped = tf.reshape(x, (B * T, N, F))  # (B*T, N, F)\n",
    "        attn_out = node_mha(x_reshaped, x_reshaped)  # (B*T, N, F)\n",
    "        out = tf.reshape(attn_out, (B, T, N, F))     # (B,T,N,F)\n",
    "        return out\n",
    "\n",
    "    attn_out = Lambda(apply_node_attention, name=\"node_attention\")(node_feature)  # (B,T,N,F)\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # 6. Pooling theo node: mean trên N\n",
    "    #    (B,T,N,F) -> (B,T,F)\n",
    "    # ------------------------------------------------------\n",
    "    def pool_nodes_mean(x):\n",
    "        # x: (B,T,N,F)\n",
    "        B = tf.shape(x)[0]\n",
    "        T = tf.shape(x)[1]\n",
    "        N = tf.shape(x)[2]\n",
    "        F = tf.shape(x)[3]\n",
    "        x_reshaped = tf.reshape(x, (B * T, N, F))       # (B*T,N,F)\n",
    "        pooled = tf.reduce_mean(x_reshaped, axis=1)     # (B*T,F)\n",
    "        return tf.reshape(pooled, (B, T, F))            # (B,T,F)\n",
    "\n",
    "    temporal_features = Lambda(\n",
    "        pool_nodes_mean,\n",
    "        name=\"node_mean_pool\"\n",
    "    )(attn_out)  # (B,T,F)\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # 7. LSTM theo thời gian (B,T,F) -> (B, hidden)\n",
    "    # ------------------------------------------------------\n",
    "    lstm_out = LSTM(\n",
    "        lstm_units,\n",
    "        return_sequences=False,\n",
    "        name=\"temporal_lstm\"\n",
    "    )(temporal_features)   # (B, lstm_units)\n",
    "\n",
    "    lstm_out = Dropout(dropout_rate, name=\"dropout\")(lstm_out)\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # 8. Dense -> (B, N*K) rồi reshape về (B, N, K)\n",
    "    # ------------------------------------------------------\n",
    "    hidden = Dense(64, activation=\"relu\", name=\"dense_hidden\")(lstm_out)\n",
    "\n",
    "    out_flat = Dense(\n",
    "        n_nodes * n_counters_target,\n",
    "        activation=\"linear\",\n",
    "        name=\"dense_output_flat\"\n",
    "    )(hidden)                         # (B, N*K)\n",
    "\n",
    "    out = Reshape(\n",
    "        (n_nodes, n_counters_target),\n",
    "        name=\"output_reshape\"\n",
    "    )(out_flat)                       # (B, N, K)\n",
    "\n",
    "    model = Model(\n",
    "        inputs=[counters_input, node_ids_input],\n",
    "        outputs=out,\n",
    "        name=\"LSTM_NodeCounter_Model\"\n",
    "    )\n",
    "\n",
    "    model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94980a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\acer\\anaconda3\\envs\\zhuge\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:232: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "Exception encountered when calling Lambda.call().\n\n\u001b[1mWe could not automatically infer the shape of the Lambda's output. Please specify the `output_shape` argument for this Lambda layer.\u001b[0m\n\nArguments received by Lambda.call():\n  • args=(['<KerasTensor shape=(None, 6, 16), dtype=float32, sparse=False, ragged=False, name=keras_tensor_1>', '<KerasTensor shape=(None, 24, 6, 20), dtype=float32, sparse=False, ragged=False, name=counters_input>'],)\n  • kwargs={'mask': ['None', 'None']}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m n_counters_target \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m     \u001b[38;5;66;03m# số counter muốn dự đoán cho mỗi node\u001b[39;00m\n\u001b[0;32m      5\u001b[0m n_nodes_total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m       \u001b[38;5;66;03m# tổng số node_id có thể có trong hệ thống (embedding)\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_lstm_node_counter_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_past\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_past\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_nodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_nodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_counters_total\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_counters_total\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_counters_target\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_counters_target\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_nodes_total\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_nodes_total\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcounter_latent_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnode_emb_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlstm_units\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\n\u001b[0;32m     16\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n",
      "Cell \u001b[1;32mIn[5], line 94\u001b[0m, in \u001b[0;36mbuild_lstm_node_counter_model\u001b[1;34m(n_past, n_nodes, n_counters_total, n_counters_target, n_nodes_total, counter_latent_dim, node_emb_dim, lstm_units, dropout_rate)\u001b[0m\n\u001b[0;32m     91\u001b[0m     node_emb_exp \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mtile(node_emb_exp, [B, T, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m node_emb_exp\n\u001b[1;32m---> 94\u001b[0m node_emb_broadcast \u001b[38;5;241m=\u001b[39m \u001b[43mLambda\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbroadcast_node_emb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbroadcast_node_embedding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m     97\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnode_emb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcounters_input\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (B,T,N,E)\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------------\u001b[39;00m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;66;03m# 4. Ghép counter latent + node embedding  => (B,T,N,F)\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------------\u001b[39;00m\n\u001b[0;32m    102\u001b[0m node_feature \u001b[38;5;241m=\u001b[39m Concatenate(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconcat_counter_node\u001b[39m\u001b[38;5;124m\"\u001b[39m)(\n\u001b[0;32m    103\u001b[0m     [encoded_counters, node_emb_broadcast]\n\u001b[0;32m    104\u001b[0m )  \u001b[38;5;66;03m# (B,T,N,H+E)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\acer\\anaconda3\\envs\\zhuge\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\acer\\anaconda3\\envs\\zhuge\\lib\\site-packages\\keras\\src\\layers\\core\\lambda_layer.py:95\u001b[0m, in \u001b[0;36mLambda.compute_output_shape\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m tree\u001b[38;5;241m.\u001b[39mmap_structure(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mshape, output_spec)\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m---> 95\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m     96\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWe could not automatically infer the shape of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     97\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe Lambda\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms output. Please specify the `output_shape` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     98\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margument for this Lambda layer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     99\u001b[0m         )\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_shape):\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_shape(input_shape)\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: Exception encountered when calling Lambda.call().\n\n\u001b[1mWe could not automatically infer the shape of the Lambda's output. Please specify the `output_shape` argument for this Lambda layer.\u001b[0m\n\nArguments received by Lambda.call():\n  • args=(['<KerasTensor shape=(None, 6, 16), dtype=float32, sparse=False, ragged=False, name=keras_tensor_1>', '<KerasTensor shape=(None, 24, 6, 20), dtype=float32, sparse=False, ragged=False, name=counters_input>'],)\n  • kwargs={'mask': ['None', 'None']}"
     ]
    }
   ],
   "source": [
    "n_past = 24               # số time steps quá khứ\n",
    "n_nodes = 6               # số node hiện có trong dữ liệu\n",
    "n_counters_total = 20     # tổng số counter mỗi node\n",
    "n_counters_target = 3     # số counter muốn dự đoán cho mỗi node\n",
    "n_nodes_total = 100       # tổng số node_id có thể có trong hệ thống (embedding)\n",
    "\n",
    "model = build_lstm_node_counter_model(\n",
    "    n_past=n_past,\n",
    "    n_nodes=n_nodes,\n",
    "    n_counters_total=n_counters_total,\n",
    "    n_counters_target=n_counters_target,\n",
    "    n_nodes_total=n_nodes_total,\n",
    "    counter_latent_dim=8,\n",
    "    node_emb_dim=16,\n",
    "    lstm_units=64\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf24832",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict([X_test, node_ids])  # (B_test, n_nodes, n_counters_target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zhuge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
